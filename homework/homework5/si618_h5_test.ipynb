{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d791c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sijuntao_si618_hw5_part1.py\n"
     ]
    }
   ],
   "source": [
    "%%file  sijuntao_si618_hw5_part1.py\n",
    "\n",
    "import mrjob\n",
    "import nltk\n",
    "import re\n",
    "from mrjob.job import MRJob\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "pattern = r'\\b[A-Za-z]{4,}\\b'\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "class MRMostUsedWordStems(MRJob):\n",
    "    OUTPUT_PROTOCOL = mrjob.protocol.TextProtocol\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        try:\n",
    "            congress = line.split('\\t')[4]  # congress\n",
    "            if line != '' and line is not None:\n",
    "                origin_word_list = re.findall(pattern, line)\n",
    "                for origin_word in origin_word_list:\n",
    "                    stem_word = stemmer.stem(origin_word)\n",
    "                    yield (congress, stem_word), 1\n",
    "        except:\n",
    "            pass\n",
    "       \n",
    "    def combiner(self, word_stem, counts):\n",
    "        # sums up the count for each (congress, stem) pair\n",
    "        yield word_stem, sum(counts)\n",
    "\n",
    "    def reducer(self, word_stem, counts):\n",
    "        # gets the final list of counts for each (congress, word_stem)\n",
    "        yield  word_stem[0] + \"\\t\" + word_stem[1], str(sum(counts))\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MRMostUsedWordStems.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba47c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Running step 1 of 1...\n",
      "Creating temp directory /var/folders/10/lx3rh6q956qc768glw5ktj600000gn/T/sijuntao_si618_hw5_part1.junsi.20221001.170609.590628\n",
      "job output is in ./output_part1\n",
      "Removing temp directory /var/folders/10/lx3rh6q956qc768glw5ktj600000gn/T/sijuntao_si618_hw5_part1.junsi.20221001.170609.590628...\n"
     ]
    }
   ],
   "source": [
    "!python3 sijuntao_si618_hw5_part1.py ./bills -o ./output_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5467694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./output_part1/part* > sijuntao_si618_hw5_output_part1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b5e5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff sijuntao_si618_hw5_output_part1.txt si618_hw4_part1_desired_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103945c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sijuntao_si618_hw5_part2.py\n"
     ]
    }
   ],
   "source": [
    "%%file  sijuntao_si618_hw5_part2.py\n",
    "\n",
    "import mrjob\n",
    "import nltk\n",
    "import re\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "pattern = r'\\b[A-Za-z]{4,}\\b'\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "class MRMostUsedWordStems(MRJob):\n",
    "    OUTPUT_PROTOCOL = mrjob.protocol.TextProtocol\n",
    "\n",
    "    def mapper_get_word_stems(self, _, line):\n",
    "        try:\n",
    "            if line != '' and line is not None:\n",
    "                origin_word_list = re.findall(pattern, line)\n",
    "                for origin_word in origin_word_list:\n",
    "                    stem_word = stemmer.stem(origin_word)\n",
    "                    yield stem_word, 1\n",
    "        except:\n",
    "            pass\n",
    "       \n",
    "    def combiner_count_word_stems(self, word_stem, counts):\n",
    "        # sums up the count for each stem\n",
    "        yield word_stem, sum(counts)\n",
    "\n",
    "    def reducer_count_word_stems(self, word_stem, counts):\n",
    "        # gets the tuple of (stem_length, (word_stem, counts))\n",
    "        yield  len(word_stem), (word_stem, sum(counts))\n",
    "        \n",
    "    def reducer_find_max_word_stem(self, length, word_stem_count_pairs):\n",
    "        # gets most frequent word stem for each word stem length\n",
    "        max_word_stem_count_pairs = max(word_stem_count_pairs, key = lambda pair: list(pair)[1])\n",
    "        yield  str(length) + '\\t' + list(max_word_stem_count_pairs)[0], str(list(max_word_stem_count_pairs)[1])\n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper = self.mapper_get_word_stems,\n",
    "                   combiner = self.combiner_count_word_stems,\n",
    "                   reducer = self.reducer_count_word_stems),\n",
    "            MRStep(reducer = self.reducer_find_max_word_stem)\n",
    "        ]\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MRMostUsedWordStems.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5ed933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Running step 1 of 2...\n",
      "Creating temp directory /var/folders/10/lx3rh6q956qc768glw5ktj600000gn/T/sijuntao_si618_hw5_part2.junsi.20221001.170907.394330\n",
      "Running step 2 of 2...\n",
      "job output is in ./output_part2\n",
      "Removing temp directory /var/folders/10/lx3rh6q956qc768glw5ktj600000gn/T/sijuntao_si618_hw5_part2.junsi.20221001.170907.394330...\n"
     ]
    }
   ],
   "source": [
    "!python3 sijuntao_si618_hw5_part2.py ./bills -o ./output_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e059fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./output_part2/part* > sijuntao_si618_hw5_output_part2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84d92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff sijuntao_si618_hw5_output_part2.txt si618_hw4_part2_desired_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7c202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
