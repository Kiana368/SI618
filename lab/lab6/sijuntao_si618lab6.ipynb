{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0d23d3",
   "metadata": {},
   "source": [
    "# SI 618 F22 Lab 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30373d",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "The output of input_file.take(5) should look exactly like this\n",
    "\n",
    "` \n",
    "[\"I'Alg\\t1850\\t1\\t1\",\n",
    " \"I'Alg\\t1855\\t2\\t2\",\n",
    " \"I'Alg\\t1883\\t1\\t1\",\n",
    " \"I'Alg\\t1886\\t3\\t3\",\n",
    " \"I'Alg\\t1939\\t1\\t1\"]\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb399d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary Spark library classes\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# Grab the input and output path\n",
    "input_path = '/scratch/siads618f22_class_root/siads618f22_class/shared_data/lab6_data'\n",
    "output_path = './ngram_out/'\n",
    "\n",
    "# Create a configuration for this Spark job\n",
    "conf = SparkConf().setAppName('AnnualWordLength').set(\"spark.hadoop.validateOutputSpecs\", \"false\")\n",
    "\n",
    "# Create a context for the job. The context is used to manage the job at a\n",
    "# high level.\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439ec29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = sc.textFile(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ba6b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'Alg\\t1850\\t1\\t1\",\n",
       " \"I'Alg\\t1855\\t2\\t2\",\n",
       " \"I'Alg\\t1883\\t1\\t1\",\n",
       " \"I'Alg\\t1886\\t3\\t3\",\n",
       " \"I'Alg\\t1896\\t2\\t2\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab15032",
   "metadata": {},
   "source": [
    "### 1.\tTransform each line of the original dataset into an array of the form [1gram, year, occurrences, volumes]. Store the transformed dataset in \"data\". (Hint: use map transformation)\n",
    "The output of data.take(5) should look exactly like this\n",
    "\n",
    "`\n",
    "[[\"I'Alg\", '1850', '1', '1'],\n",
    " [\"I'Alg\", '1855', '2', '2'],\n",
    " [\"I'Alg\", '1883', '1', '1'],\n",
    " [\"I'Alg\", '1886', '3', '3'],\n",
    " [\"I'Alg\", '1896', '2', '2'],]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89394efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_file.map(lambda line: line.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6ce94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"I'Alg\", '1850', '1', '1'],\n",
       " [\"I'Alg\", '1855', '2', '2'],\n",
       " [\"I'Alg\", '1883', '1', '1'],\n",
       " [\"I'Alg\", '1886', '3', '3'],\n",
       " [\"I'Alg\", '1896', '2', '2']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471932b6",
   "metadata": {},
   "source": [
    "### 2.\tCreate a new dataset \"length\" with each row containing an array of the form [year, sum_of_the_length_of_all_words_in_that_year]. \n",
    "Hint: A word could occur multiple times in a year, and you will need to count that word multiple times when calculating the total length.\n",
    "\n",
    "Remember to convert the string values to integer in the map function. \n",
    "\n",
    "The output of length.take(5) should look like this\n",
    "\n",
    "`\n",
    "[(1938, 2021053404),\n",
    " (1836, 551487404),\n",
    " (1734, 13722773),\n",
    " (1632, 57106),\n",
    " (1837, 508248822),]\n",
    " `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16181323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each row to a (year, sum of length of one word in that year) pair\n",
    "lengthAll = data.map(lambda info: (int(info[1]), int(info[2])*len(info[0])))\n",
    "# reduce lengthAll to length\n",
    "length = lengthAll.reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8eba3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1938, 2021053404),\n",
       " (1836, 551487404),\n",
       " (1734, 13722773),\n",
       " (1632, 57106),\n",
       " (1837, 508248822)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2afe29",
   "metadata": {},
   "source": [
    "### 3.\tCreate a new dataset \"count\" with each row containing an array of the form [year, total_number of words]\n",
    "The output of count.take(5) should look like this\n",
    "\n",
    "`\n",
    "[(1938, 288113442.0),\n",
    " (1836, 80514369.0),\n",
    " (1734, 2123777.0),\n",
    " (1632, 8382.0),\n",
    " (1939, 285347395.0),]\n",
    " `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b09584",
   "metadata": {},
   "outputs": [],
   "source": [
    "countAll = data.map(lambda info: (int(info[1]), float(info[2])))\n",
    "count = countAll.reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dcbef79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1938, 288113442.0),\n",
       " (1836, 80514369.0),\n",
       " (1734, 2123777.0),\n",
       " (1632, 8382.0),\n",
       " (1939, 285347395.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e9039",
   "metadata": {},
   "source": [
    "### 4.\tCreate a new dataset \"avgLength\" with each row containing an array of the form [year, average word length] by dividing length by words. (Hint: join the length and count first and use map to obtain the new dataset)\n",
    "\n",
    "The output of avgLength.take(5) should look like this\n",
    "\n",
    "`\n",
    "[(1938, 7.014783447694884),\n",
    " (1836, 6.84955258110512),\n",
    " (1734, 6.461494309430792),\n",
    " (1632, 6.812932474349797),\n",
    " (1939, 7.041908533981886),]\n",
    " `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6472ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgLength = length.join(count).map(lambda lc_info: (lc_info[0], lc_info[1][0]/lc_info[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98ed6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1938, 7.014783447694884),\n",
       " (1836, 6.84955258110512),\n",
       " (1734, 6.461494309430792),\n",
       " (1632, 6.812932474349797),\n",
       " (1939, 7.041908533981886)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgLength.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ca7b6",
   "metadata": {},
   "source": [
    "### 5. Sort the results by year in chronological order\n",
    "\n",
    "The output of avgLengthSorted.take(5) should look like this\n",
    "\n",
    "`\n",
    "[(1505, 6.618036653964798),\n",
    " (1507, 6.304188864514781),\n",
    " (1515, 7.488374666097649),\n",
    " (1520, 6.245398773006135),\n",
    " (1524, 7.282010767790262)]\n",
    " `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "334027a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1505, 6.618036653964798),\n",
       " (1507, 6.304188864514781),\n",
       " (1515, 7.488374666097649),\n",
       " (1520, 6.245398773006135),\n",
       " (1524, 7.282010767790262)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgLengthSorted = avgLength.sortBy(lambda a_info: a_info[0], ascending = True)\n",
    "avgLengthSorted.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d86a00",
   "metadata": {},
   "source": [
    "### 6. Save the results in the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684ca813",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgLengthSorted.saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "901e41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let Spark know that the job is done.\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7bcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the results to one file\n",
    "!cat ./ngram_out/part* >  sijuntao_ngrams_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b3461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "96890b704896806e1b70ec3468f2aa0caaad9a2f3cc76dad48e7dacf13d55fab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
